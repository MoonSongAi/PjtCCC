# streamlit_app.py
import streamlit as st
# from streamlit_chat import message
from langchain_community.callbacks import get_openai_callback
from langchain.memory import StreamlitChatMessageHistory
from langchain_integration import is_vector_db ,load_langchain,  setup_langchain
from analysis_image import save_image_to_folder ,load_to_image , \
                        get_image_base64,process_image_with_hsv_range 
from text_detection_comparison import TextDetectionAndComparison
from streamlit_cropper import st_cropper
from OCR_anal import specialDicForOCR , execute_OCR
from PIL import Image
import numpy as np
import os


# ì´ë¯¸ì§€ ì‚­ì œ í•¨ìˆ˜
def delete_image(image_index):
    if 0 <= image_index < len(st.session_state.saved_images):
        del st.session_state.saved_images[image_index]
        del st.session_state.images_list[image_index]
        del st.session_state.process_images[image_index]
        del st.session_state.process_list[image_index]
        # ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ ë³€ê²½ í›„ ë‹¤ì‹œ ì´ë¯¸ì§€ì™€ ë²„íŠ¼ í‘œì‹œë¥¼ ìœ„í•´ í˜ì´ì§€ ê°±ì‹ 
        if len(st.session_state.images_list) == 0:
            st.session_state.anal_button_click = False
        st.rerun()

def main():
    # Google Cloud ìê²© ì¦ëª… íŒŒì¼ì˜ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ì—¬ í´ë˜ìŠ¤ ì´ˆê¸°í™”
    # detector = TextDetectionAndComparison("C:\\keys\\feisty-audio-420101-460dfe33e2cb.json")
    
    # OCRì„ ìœ„í•œ ì‚¬ì „ ì¤€ë¹„ ì‘ì—…
    myDic = specialDicForOCR()

    DB_INDEX = "VECTOR_DB_INDEX"
    st.set_page_config(
        page_title="í‘œì‹œ ë””ìì¸",
        page_icon=":volcano:")


    st.title("_í‘œì‹œ ë””ìì¸ ì˜¤ë¥˜ íƒìƒ‰ê¸°_ :red[QA Chat]:volcano:")
    # ì—¬ê¸°ì— CSS ìŠ¤íƒ€ì¼ì„ ì¶”ê°€
    st.markdown("""
        <style>
        /* ì—¬ê¸°ì— CSS ìŠ¤íƒ€ì¼ì„ ì¶”ê°€ */
        #tabs-bui3-tab-0>.st-emotion-cache-l9bjmx p,
        #tabs-bui3-tab-1>.st-emotion-cache-l9bjmx p,
        #tabs-bui3-tab-2>.st-emotion-cache-l9bjmx p{
        /* íƒ­ ì•„ì´í…œ ìŠ¤íƒ€ì¼ ë³€ê²½ */
            font-size:25px
        }
        .element-container iframe{
                border:3px dashed black
        }
            
        .st-emotion-cache-1kyxreq div{
                border:3px dashed red
        }
                
        .st-emotion-cache-7ym5gk{
                width:14rem;
                height:5rem
        }
        </style>
    """, unsafe_allow_html=True)
    

    tab1 , tab2 ,tab3 = st.tabs(["ğŸ’«Image processing","ğŸ§‘â€ğŸš€chat about Design","ğŸ•µï¸â€â™‚ï¸ chuncked Data"])

    if "conversation" not in st.session_state:
        st.session_state.conversation = None

    if "chat_history" not in st.session_state:
        st.session_state.chat_history = None

    if "processComplete" not in st.session_state:
        st.session_state.processComplete = None
    # 1ë‹¨ê³„: ì´ˆê¸° ìƒíƒœ ì„¤ì •
    if 'canvas_image_data' not in st.session_state:
        st.session_state.canvas_image_data = None
    # íšŒì „ëœ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  session_state ì´ˆê¸°í™”
    if 'rotation_angle' not in st.session_state:
        st.session_state.rotation_angle = 0
    if 'saved_images' not in st.session_state:
        st.session_state.saved_images = []
    if 'process_images' not in st.session_state:
        st.session_state.process_images = []
    if 'ocr_images' not in st.session_state:
        st.session_state.ocr_images = []
    if 'images_list' not in st.session_state:
        st.session_state.images_list = []
    if 'process_list' not in st.session_state:
        st.session_state.process_list = []
    if 'ocr_list' not in st.session_state:
        st.session_state.ocr_list = []
    if 'loaded_image' not in st.session_state:
        st.session_state.loaded_image = None
    if 'anal_process' not in st.session_state:
        st.session_state.anal_process = False
    if 'anal_button_click' not in st.session_state:
        st.session_state.anal_button_click = False
    if 'delete_request' not in st.session_state:
        st.session_state.delete_request = False
    if 'vector_db' not in st.session_state:
        st.session_state.vector_db = is_vector_db(DB_INDEX)   
    if 'anal_image_data' not in st.session_state:
        st.session_state.anal_image_data = [] 

    with st.sidebar:
        with st.expander("Adjust HSV Threshold",expanded=False):
            colors = ["Red", "Green", "Blue", "Yellow", "Black"]
            default_color = "Black"             # ê¸°ë³¸ìœ¼ë¡œ ì„ íƒí•˜ê³  ì‹¶ì€ ìƒ‰ìƒ
            default_index = colors.index(default_color)  # 'Black'ì˜ ì¸ë±ìŠ¤ ì°¾ê¸°
            color_selection = st.selectbox("Select line color", colors, index=default_index)
            if color_selection == "Red":
                # í´ë¦­í•œ HSV ìƒ‰ìƒ:  [174 250 209]
                lower =  [164,210,159]
                upper =  [179,255,255]
                # lower = [0, 100, 100] 
                # upper = [10, 255, 255]
            elif color_selection == "Green":
                lower = [40,40,40]
                upper = [80,255,255]
            elif color_selection == "Blue":
                lower = [40,40,40]
                upper = [80,255,255]
            elif color_selection == "Green":
                lower = [40,40,40]
                upper = [80,255,255]
            elif color_selection == "Black":
                #í´ë¦­í•œ HSV ìƒ‰ìƒ:  [ 89 255  84]
                lower = [79, 215, 34]
                upper = [99, 255, 134]
                # lower = [0, 0, 0]
                # upper = [180, 255, 50]
            else:
                lower = [0,100,100]
                upper = [10,255,255]

            lower_h = st.slider('Lower Hue', 0, 179, lower[0])
            lower_s = st.slider('Lower Saturation', 0, 255, lower[1])
            lower_v = st.slider('Lower Value', 0, 255, lower[2])
            upper_h = st.slider('Upper Hue', 0, 179, upper[0])
            upper_s = st.slider('Upper Saturation', 0, 255, upper[1])
            upper_v = st.slider('Upper Value', 0, 255, upper[2])

            lower_hsv = np.array([lower_h, lower_s, lower_v])
            upper_hsv = np.array([upper_h, upper_s, upper_v])

        with st.expander("Select Image",expanded=True):            
            uploaded_Image =  st.file_uploader("Select target Image",type=['pdf','png','jpg'])
            # íŒŒì¼ì´ ì—…ë¡œë“œ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³  ë²„íŠ¼ì˜ í™œì„±í™” ìƒíƒœ ê²°ì •
                # pDF image í•´ìƒ
            pdf_value = st.slider(
                    label='PDF Resolution',  # ìŠ¬ë¼ì´ë” ë¼ë²¨
                    min_value=1,  # ìµœì†Œê°’
                    max_value=10,  # ìµœëŒ€ê°’
                    value=2,  # ê¸°ë³¸ê°’
                    step=1  # ë‹¨ê³„
            )
            print('st.expander:',st.session_state.anal_process)

            process_image = st.button("Analysis Design file....", disabled= not st.session_state.anal_process)
            if process_image:
               st.session_state.anal_button_click = True  #Button Click ì„ session ë™ì•ˆ ìœ ì§€ í•˜ê¸°ìœ„í•´ì„œ 

        with st.expander("Setting for LangChain",expanded=False):            
            openai_api_key = st.text_input("OpenAI API Key", key="chatbot_api_key", type="password")
            model_name = st.selectbox(
                "Choose the model for OpenAI LLM API",
                options=['gpt-3.5-turbo', 'gpt-3', 'gpt-4','davinci-codex', 'curie'],  # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì´ë¦„ë“¤
                index=0  # 'gpt-3.5-turbo'ë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
            )

            load_lang = st.button("load vector DB", disabled= not st.session_state.vector_db)

            uploaded_files =  st.file_uploader("Upload your file",type=['pdf','docx'],accept_multiple_files=True)
            # Streamlit ì‚¬ì´ë“œë°”ì— ìŠ¬ë¼ì´ë” ì¶”ê°€
            chunk_size = st.slider("Chunk Size", min_value=100, max_value=2000, value=900, step=50)
            chunk_overlap = st.slider("Chunk Overlap", min_value=50, max_value=500, value=100, step=10)
            # Streamlit ì‚¬ì´ë“œë°” ì½¤ë³´ë°•ìŠ¤ ì¶”ê°€
            device_option = st.selectbox(
                "Choose the device for the model",
                options=['cpu', 'cuda', 'cuda:0', 'cuda:1'],  # ì—¬ê¸°ì— í•„ìš”í•œ ëª¨ë“  ì˜µì…˜ì„ ì¶”ê°€í•˜ì„¸ìš”.
                index=0  # 'cpu'ë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
            )
            # íŒŒì¼ì´ ì—…ë¡œë“œ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³  ë²„íŠ¼ì˜ í™œì„±í™” ìƒíƒœ ê²°ì •
            button_enabled = uploaded_files is not None and len(uploaded_files) > 0
            process_lang = st.button("Process....", disabled=not button_enabled)

    if uploaded_Image:
        if st.session_state.loaded_image != uploaded_Image:    #imageê°€ ë³€ê²½ë˜ì—ˆë‹¤ë©´
            st.sidebar.write("New image loading...........")
            st.session_state.loaded_image = uploaded_Image
            st.session_state.saved_images = []
            st.session_state.images_list = []
            st.session_state.process_images = []
            st.session_state.process_list = []
            st.session_state.ocr_images = []
            st.session_state.ocr_list = []
            st.session_state.anal_image_data = [] 
            del_buttons = []

            st.session_state.anal_process = False

        with tab1:
            img = load_to_image(uploaded_Image,pdf_value)
            cropped_img = st_cropper(img, realtime_update=True, box_color='#FF0000',
                                                    aspect_ratio=(1,1))
                        
            # Manipulate cropped image at will
            st.session_state.canvas_image_data = cropped_img
            # _ = cropped_img.thumbnail((300,300))

            col1, col2  = st.columns(2)
            with col1:
                # ì´ë¯¸ì§€ íšŒì „ ë²„íŠ¼
                rotate_image = st.button("Rotate cropped image")
            with col2:
                # ì´ë¯¸ì§€ ì €ì¥ ë²„íŠ¼
                save_image = st.button("Save cropped image")
            if rotate_image:
                st.session_state.rotation_angle -= 90   # íšŒì „ ê°ë„ ì—…ë°ì´íŠ¸
                st.session_state.rotation_angle %= 360  # 360ë„ê°€ ë˜ë©´ 0ìœ¼ë¡œ ë¦¬ì…‹
                # í˜„ì¬ íšŒì „ ê°ë„ì— ë”°ë¼ ì´ë¯¸ì§€ íšŒì „
            st.session_state.canvas_image_data = st.session_state.canvas_image_data.rotate(
                                                              st.session_state.rotation_angle,
                                                              expand = True)
            print(f"st.session_state.rotation_angle={st.session_state.rotation_angle}")

            if save_image:
                save_name = save_image_to_folder(st.session_state.canvas_image_data)
                # ì €ì¥ëœ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ì— ì´ë¯¸ì§€ ì¶”ê°€
                st.session_state.saved_images.append(st.session_state.canvas_image_data)
                st.session_state.images_list.append(save_name)


            st.write("***_:blue[Preview Cropped Image]_***")
            st.image(st.session_state.canvas_image_data)
            st.session_state.anal_process = True
            # ì €ì¥ëœ ì´ë¯¸ì§€ ì¸ë„¤ì¼ì„ íš¡ìœ¼ë¡œ ë‚˜ì—´í•˜ì—¬ í‘œì‹œ
            if st.session_state.saved_images:
                # ê° ì´ë¯¸ì§€ë¥¼ ì‘ì€ ì¸ë„¤ì¼ë¡œ ë³€í™˜í•˜ì—¬ í‘œì‹œ
                cols = st.columns(len(st.session_state.saved_images))
                for idx, saved_image in enumerate(st.session_state.saved_images):
                    with cols[idx]:
                        # ì¸ë„¤ì¼ í¬ê¸°ë¡œ ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ
                        thumbnail_images = st.session_state.saved_images[idx].copy()
                        st.caption(st.session_state.images_list[idx])
                        thumbnail_images.thumbnail((200, 200))
                        st.image(thumbnail_images, width=100)  # ì¸ë„¤ì¼ ì´ë¯¸ì§€ í‘œì‹œ
                        # ì‚­ì œ ë²„íŠ¼ ìƒì„±
                        if st.button(f'Delete {idx}', key=f"delete_{idx}"):
                            st.session_state.delete_request = True
                            delete_image(idx)   # ì‚­ì œ ë²„íŠ¼ì´ í´ë¦­ë˜ë©´, í•´ë‹¹ ì´ë¯¸ì§€ë¥¼ ì‚­ì œí•˜ê¸° ìœ„í•œ í”Œë˜ê·¸ ì„¤ì •

            if st.session_state.anal_button_click:
                # ìƒˆë¡œìš´ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ê¸° ì „ì— ê¸°ì¡´ì˜ Zoom In ìƒíƒœë¥¼ ì´ˆê¸°í™”í•˜ê±°ë‚˜ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
                for idx, _ in enumerate(st.session_state.images_list):
                    zoom_key = f"zoom_{idx}"
                    # session_stateì— í™•ëŒ€ ìƒíƒœë¥¼ ì €ì¥í•  ë³€ìˆ˜ê°€ ì—†ìœ¼ë©´ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
                    if zoom_key not in st.session_state:
                        st.session_state[zoom_key] = False

                # ì„ íƒëœ ì´ë¯¸ì§€ ì´ë¦„ìœ¼ë¡œ ì‹¤ì œ ì´ë¯¸ì§€ ê°ì²´ë¥¼ ì–»ìŒ
                cols = st.columns(len(st.session_state.images_list))
                for idx, img_path in enumerate(st.session_state.images_list):
                    # print(len(st.session_state.process_list)-1,idx)
                    if len(st.session_state.process_list)-1 < idx:  #ìƒˆë¡œìš´ ì´ë¯¸ì§€ê°€ ì¶”ê°€ëœ ê²½ìš°ë§Œ
                        image = Image.open(img_path).convert('RGB')
                        processed_image = process_image_with_hsv_range(image, lower_hsv, upper_hsv)
                    
                        # ì €ì¥ëœ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ì— ì´ë¯¸ì§€ ì¶”ê°€
                        st.session_state.process_images.append(processed_image)
                        save_name = save_image_to_folder(processed_image)
                        st.session_state.process_list.append(save_name)

                if len(st.session_state.process_list) > 0:
                    # print(st.session_state.process_list)
                    for idx, img_path in enumerate(st.session_state.process_list):
                        zoom_key = f"zoom_{idx}"                       
                        with cols[idx]:
                            # í™”ë©´ì— í‘œì‹œí•˜ê¸° ìœ„í•´ ì¸ë„¤ì¼ ì´ë¯¸ì§€ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.
                            display_image = st.session_state.process_images[idx].copy()
                            display_image.thumbnail((200, 200))
                            st.image(display_image, width=100)  # ì¸ë„¤ì¼ ì´ë¯¸ì§€ë¡œ í‘œì‹œ

                            # 'Zoom In' ë²„íŠ¼ í´ë¦­ ì‹œ ì²˜ë¦¬
                            if st.button(f'Zoom In {idx}', key=f"zoomin_{idx}"):
                                # í™•ëŒ€ ìƒíƒœë¥¼ í† ê¸€í•©ë‹ˆë‹¤.
                                st.session_state[zoom_key] = not st.session_state[zoom_key]
                            
                            # í™•ëŒ€ ìƒíƒœì— ë”°ë¼ ì´ë¯¸ì§€ë¥¼ í‘œì‹œí•˜ê±°ë‚˜ ìˆ¨ê¹ë‹ˆë‹¤.
                            if st.session_state[zoom_key]:
                                st.image(st.session_state.process_images[idx], width=700)

                        if  len(st.session_state.anal_image_data) <= idx: 
                            st.session_state.anal_image_data.append(None)  # ì´ë¯¸ì§€ ì²˜ë¦¬ ê²°ê³¼ ëŒ€ì‹  None ì¶”ê°€
                        # ì´ë¯¸ì§€ ì²˜ë¦¬ ê²°ê³¼ê°€ ì´ë¯¸ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ìƒˆë¡œ ì²˜ë¦¬
                        if st.session_state.anal_image_data[idx] is None:
                            # ì´ë¯¸ì§€ ì²˜ë¦¬ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ê²°ê³¼ë¥¼ ì €ì¥
                            ret_image = execute_OCR(myDic, img_path)
                            st.session_state.anal_image_data[idx] = ret_image

                        # ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ í‘œì‹œ
                        if st.session_state.anal_image_data[idx] is not None:
                            st.image(st.session_state.anal_image_data[idx])

    if not openai_api_key:
       openai_api_key = st.secrets["OpenAI_Key"]
       if not openai_api_key:
          st.info("Please add your OpenAI API key to continue.")
          st.stop()

    if load_lang:
        conversation_chain = load_langchain(DB_INDEX,device_option,openai_api_key,model_name)
        st.session_state.conversation = conversation_chain
        st.session_state.processComplete = True

    if process_lang:
        conversation_chain = setup_langchain(st , tab3, 
                                            uploaded_files,
                                            chunk_size,chunk_overlap,device_option,
                                            openai_api_key,model_name)
        st.session_state.conversation = conversation_chain
        st.session_state.processComplete = True

    with tab2:
        # ë²„íŠ¼ì— í‘œì‹œë  ë‚´ìš©ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ì˜
        button_labels = ["ê¸€ìí¬ê¸°ì™€ ì¥í‰ ê°€ì´ë“œë¼ì¸",
                         "ì›ì‚°ì§€ í‘œì‹œë²•",
                         "êµµê²Œ í‘œì‹œí•´ì•¼í•˜ëŠ” í•­ëª©ì€ ë¬´ì—‡ì´ ìˆë‚˜ìš”?",
                         "ì˜ì–‘ì •ë³´ í‘œì‹œí• ë•Œ ì£¼ì˜ì‚¬í•­ì€?",
                         "ì›ì¬ë£Œ í‘œì‹œ ê¸°ì¤€",
                         "ì •ë³´í‘œì‹œë©´ í‘œì‹œë°©ë²•"]
            # 2í–‰ 3ì—´ êµ¬ì¡°ë¡œ ë²„íŠ¼ì„ ë°°ì¹˜í•˜ê¸° ìœ„í•œ ì¸ë±ìŠ¤
        if 'last_clicked' not in st.session_state:
            st.session_state['last_clicked'] = ''

        idx = 0
        # ë‘ í–‰ì„ ìƒì„±
        for i in range(2):  # ë‘ í–‰
            cols = st.columns(3)
            for col in cols:  # ê° í–‰ì— 3ê°œì˜ ì—´
                if idx < len(button_labels):
                    button_key = f"button_{idx}"
                    if col.button(button_labels[idx], key=button_key):
                        # ë²„íŠ¼ í´ë¦­ ì‹œ, í•´ë‹¹ ë²„íŠ¼ì˜ ë ˆì´ë¸”ì„ ì €ì¥
                        st.session_state['last_clicked'] = button_labels[idx]
                    idx += 1

        if 'messages' not in st.session_state:
            st.session_state['messages'] = [{"role": "assistant", 
                                            "content": "ì•ˆë…•í•˜ì„¸ìš”! í‘œì‹œë””ìì¸ê³¼ ê´€ë ¨ëœ ê¶ê¸ˆí•˜ì‹  ê²ƒì´ ìˆìœ¼ë©´ ë¬´ì—‡ì´ë“  ì§ˆë¬¸ í•˜ì„¸ìš”!"}]
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        history = StreamlitChatMessageHistory(key="chat_messages")

        # Chat logic
        if st.session_state['last_clicked'] != '':
            query_text =  st.session_state['last_clicked']
            st.session_state['last_clicked'] = ''
            query = query_text
            st.chat_input(query_text)
        else:
            query_text = "ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
            query = st.chat_input(query_text)

        if query:
            st.session_state.messages.append({"role": "user", "content": query})

            with st.chat_message("user"):
                st.markdown(query)

            with st.chat_message("assistant"):
                chain = st.session_state.conversation
                if chain is None:
                    st.warning('í•™ìŠµëœ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.')
                    st.stop()

                with st.spinner("Thinking..."):
                    result = chain({"question": query})
                    with get_openai_callback() as cb:
                        st.session_state.chat_history = result['chat_history']
                    response = result['answer']
                    st.session_state.messages.append({"role": "assistant", "content": response})

                    source_documents = result['source_documents']

                    st.markdown(response)
                    with st.expander("ì°¸ê³  ë¬¸ì„œ í™•ì¸"):
                        st.markdown(source_documents[0].metadata['source'], help = source_documents[0].page_content)
                        st.markdown(source_documents[1].metadata['source'], help = source_documents[1].page_content)
                        st.markdown(source_documents[2].metadata['source'], help = source_documents[2].page_content)


if __name__ == '__main__':
    main()