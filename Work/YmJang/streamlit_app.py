# streamlit_app.py
import streamlit as st
# from streamlit_chat import message
from langchain_community.callbacks import get_openai_callback
from langchain.memory import StreamlitChatMessageHistory
from image_processing import process_image_with_hsv_range  # í•¨ìˆ˜ ì´ë¦„ ë³€ê²½ ë° ì¸ì ì¶”ê°€

from langchain_integration import setup_langchain
from analysis_image import save_image_to_folder ,load_to_image

from streamlit_cropper import st_cropper
from PIL import Image
import numpy as np

import os


def main():
    st.set_page_config(
        page_title="í‘œì‹œ ë””ìì¸",
        page_icon=":volcano:")


    st.title("_í‘œì‹œ ë””ìì¸ ì˜¤ë¥˜ íƒìƒ‰ê¸°..._ :red[QA Chat]_ :volcano:")
    # ì—¬ê¸°ì— CSS ìŠ¤íƒ€ì¼ì„ ì¶”ê°€
    st.markdown("""
        <style>
        /* ì—¬ê¸°ì— CSS ìŠ¤íƒ€ì¼ì„ ì¶”ê°€ */
        #tabs-bui3-tab-0>.st-emotion-cache-l9bjmx p,
        #tabs-bui3-tab-1>.st-emotion-cache-l9bjmx p,
        #tabs-bui3-tab-2>.st-emotion-cache-l9bjmx p{
            /* íƒ­ ì•„ì´í…œ ìŠ¤íƒ€ì¼ ë³€ê²½ */
            font-size:25px
        }
        .element-container iframe{
                border:3px dashed black
        }
            
        .st-emotion-cache-1kyxreq div{
                border:3px dashed red
        } 
        </style>
    """, unsafe_allow_html=True)
    

    tab1 , tab2 ,tab3 = st.tabs(["ğŸ’«Image processing....","ğŸ§‘â€ğŸš€chat about Design....","ğŸ•µï¸â€â™‚ï¸ chucked Data"])

    if "conversation" not in st.session_state:
        st.session_state.conversation = None

    if "chat_history" not in st.session_state:
        st.session_state.chat_history = None

    if "processComplete" not in st.session_state:
        st.session_state.processComplete = None
    # 1ë‹¨ê³„: ì´ˆê¸° ìƒíƒœ ì„¤ì •
    if 'canvas_image_data' not in st.session_state:
        st.session_state.canvas_image_data = None
    # íšŒì „ëœ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  session_state ì´ˆê¸°í™”
    if 'rotation_angle' not in st.session_state:
        st.session_state.rotation_angle = 0
    if 'saved_images' not in st.session_state:
        st.session_state.saved_images = []
    if 'images_list' not in st.session_state:
        st.session_state.images_list = []
    if 'loaded_image' not in st.session_state:
        st.session_state.loaded_image = None
    
    # color_options ë”•ì…”ë„ˆë¦¬ ì •ì˜
    color_options = {
        "Red": ([0, 100, 100], [10, 255, 255]),
        "Green": ([50, 100, 100], [70, 255, 255]),
        "Blue": ([110, 100, 100], [130, 255, 255]),
        "Yellow": ([25, 100, 100], [35, 255, 255]),
        "Black": ([0, 0, 0], [180, 255, 30])  # HSV ë²”ìœ„ ì˜ˆì‹œ ìˆ˜ì •
    }

    with st.sidebar:
        with st.expander("Select Image",expanded=True):            
            uploaded_Image =  st.file_uploader("Select target Image",type=['pdf','png','jpg'])
            # íŒŒì¼ì´ ì—…ë¡œë“œ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³  ë²„íŠ¼ì˜ í™œì„±í™” ìƒíƒœ ê²°ì •
                # pDF image í•´ìƒ
            pdf_value = st.slider(
                    label='PDF Resolution',  # ìŠ¬ë¼ì´ë” ë¼ë²¨
                    min_value=1,  # ìµœì†Œê°’
                    max_value=10,  # ìµœëŒ€ê°’
                    value=2,  # ê¸°ë³¸ê°’
                    step=1  # ë‹¨ê³„
            )
            button_enabled = uploaded_Image is not None
            # ìƒ‰ìƒ ì„ íƒ ë“œë¡­ë‹¤ìš´ ë©”ë‰´
            selected_color_name = st.selectbox("ì´ë¯¸ì§€ ì „ì²˜ë¦¬ color_options", options=list(color_options.keys()))
            lower_hsv, upper_hsv = color_options[selected_color_name]
            process_image = st.button("Analysis Design file....", disabled=not button_enabled)


        with st.expander("Setting for LangChain",expanded=False):            
            uploaded_files =  st.file_uploader("Upload your file",type=['pdf','docx'],accept_multiple_files=True)
            # Streamlit ì‚¬ì´ë“œë°”ì— ìŠ¬ë¼ì´ë” ì¶”ê°€
            openai_api_key = st.text_input("OpenAI API Key", key="chatbot_api_key", type="password")
            chunk_size = st.slider("Chunk Size", min_value=100, max_value=2000, value=900, step=50)
            chunk_overlap = st.slider("Chunk Overlap", min_value=50, max_value=500, value=100, step=10)
            # Streamlit ì‚¬ì´ë“œë°” ì½¤ë³´ë°•ìŠ¤ ì¶”ê°€
            device_option = st.selectbox(
                "Choose the device for the model",
                options=['cpu', 'cuda', 'cuda:0', 'cuda:1'],  # ì—¬ê¸°ì— í•„ìš”í•œ ëª¨ë“  ì˜µì…˜ì„ ì¶”ê°€í•˜ì„¸ìš”.
                index=0  # 'cpu'ë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
            )
            # Streamlit ì‚¬ì´ë“œë°”  ì½¤ë³´ë°•ìŠ¤ ì¶”ê°€
            model_name = st.selectbox(
                "Choose the model for OpenAI LLM API",
                options=['gpt-3.5-turbo', 'gpt-3', 'gpt-4','davinci-codex', 'curie'],  # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì´ë¦„ë“¤
                index=0  # 'gpt-3.5-turbo'ë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
            )
            # íŒŒì¼ì´ ì—…ë¡œë“œ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³  ë²„íŠ¼ì˜ í™œì„±í™” ìƒíƒœ ê²°ì •
            button_enabled = uploaded_files is not None and len(uploaded_files) > 0
            process_lang = st.button("Process....", disabled=not button_enabled)
    if uploaded_Image:
        if st.session_state.loaded_image != uploaded_Image:    #imageê°€ ë³€ê²½ë˜ì—ˆë‹¤ë©´
            st.session_state.loaded_image = uploaded_Image
            st.session_state.saved_images = []
            st.session_state.images_list = []
        with tab1:
            img = load_to_image(uploaded_Image,pdf_value)
            cropped_img = st_cropper(img, realtime_update=True, box_color='#FF0000',
                                                    aspect_ratio=(1,1))
                        
            # Manipulate cropped image at will
            st.session_state.canvas_image_data = cropped_img
            # _ = cropped_img.thumbnail((300,300))

            # ë²„íŠ¼ ë°°ì¹˜ë¥¼ ìœ„í•œ ì»¬ëŸ¼ ìƒì„±
            col1, col2  = st.columns(2)
            with col1:
                # ì´ë¯¸ì§€ ì €ì¥ ë²„íŠ¼
                save_image = st.button("Save cropped image")
            with col2:
                # ì´ë¯¸ì§€ íšŒì „ ë²„íŠ¼
                rotate_image = st.button("Rotate cropped image")

            if rotate_image:
                st.session_state.rotation_angle += 90   # íšŒì „ ê°ë„ ì—…ë°ì´íŠ¸
                st.session_state.rotation_angle %= 360  # 360ë„ê°€ ë˜ë©´ 0ìœ¼ë¡œ ë¦¬ì…‹
                # í˜„ì¬ íšŒì „ ê°ë„ì— ë”°ë¼ ì´ë¯¸ì§€ íšŒì „
            
            st.session_state.canvas_image_data = st.session_state.canvas_image_data.rotate(
                                                              st.session_state.rotation_angle,
                                                              expand = True)

            st.write("***_:blue[Preview Cropped Image]_***")
            st.image(st.session_state.canvas_image_data)
            if save_image:
                save_name = save_image_to_folder(st.session_state.canvas_image_data)
                # ì €ì¥ëœ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ì— ì´ë¯¸ì§€ ì¶”ê°€
                st.session_state.saved_images.append(st.session_state.canvas_image_data)
                st.session_state.images_list.append(save_name)
                st.session_state.rotation_angle = 0
            # ì €ì¥ëœ ì´ë¯¸ì§€ ì¸ë„¤ì¼ì„ íš¡ìœ¼ë¡œ ë‚˜ì—´í•˜ì—¬ í‘œì‹œ
            if st.session_state.saved_images:
                # ê° ì´ë¯¸ì§€ë¥¼ ì‘ì€ ì¸ë„¤ì¼ë¡œ ë³€í™˜í•˜ì—¬ í‘œì‹œ
                cols = st.columns(len(st.session_state.saved_images))
                for idx, saved_image in enumerate(st.session_state.saved_images):
                    with cols[idx]:
                        # ì¸ë„¤ì¼ í¬ê¸°ë¡œ ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ
                        st.caption(st.session_state.images_list[idx])
                        saved_image.thumbnail((200, 200))
                        st.image(saved_image, width=100)  # ì¸ë„¤ì¼ ì´ë¯¸ì§€ í‘œì‹œ

######################## ì¶”ê°€í•¨ ###################
    
    selected_color_name = st.sidebar.selectbox("ìƒ‰ìƒ ì„ íƒ", list(color_options.keys()))
    lower_hsv, upper_hsv = color_options[selected_color_name]
    
    # "ëª¨ë“  ì´ë¯¸ì§€ ì²˜ë¦¬" ë²„íŠ¼ì„ ë©”ì¸ í˜ì´ì§€ì— ë°°ì¹˜
    if st.button('ì´ë¯¸ì§€ ì „ì²˜ë¦¬'):
        # ì²˜ë¦¬ëœ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
        if 'processed_images' not in st.session_state:
            st.session_state.processed_images = []
        
        # ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ì €ì¥
        if 'images_list' in st.session_state:
            for image_name in st.session_state.images_list:
                image_path = os.path.join('path_to_saved_images', image_name)
                pil_image = Image.open(image_path).convert('RGB')
                processed_image = process_image_with_hsv_range(pil_image, np.array(lower_hsv), np.array(upper_hsv))
                
                # ì²˜ë¦¬ëœ ì´ë¯¸ì§€ë¥¼ session_stateì— ì¶”ê°€
                st.session_state.processed_images.append(processed_image)
        
        # ì²˜ë¦¬ëœ ì´ë¯¸ì§€ë¥¼ ì¸ë„¤ì¼ í˜•íƒœë¡œ í‘œì‹œ
        if 'processed_images' in st.session_state and st.session_state.processed_images:
            cols = st.columns(len(st.session_state.processed_images))
            for idx, processed_image in enumerate(st.session_state.processed_images):
                with cols[idx]:
                    # ì¸ë„¤ì¼ ì´ë¯¸ì§€ í‘œì‹œ (PIL.Image ê°ì²´ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°)
                    st.caption(st.session_state.images_list[idx])
                    processed_image.thumbnail((200, 200))
                    st.image(processed_image, width=100)
        else:
            st.write("ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")

###################################################

    if process_lang:
        if not openai_api_key:
            openai_api_key = st.secrets["OpenAI_Key"]
            if not openai_api_key:
                st.info("Please add your OpenAI API key to continue.")
                st.stop()
        # Langchain ì„¤ì •
        conversation_chain = setup_langchain(st , tab3, 
                                            uploaded_files,
                                            chunk_size,chunk_overlap,device_option,
                                            openai_api_key,model_name)

        st.session_state.conversation = conversation_chain

        st.session_state.processComplete = True

    if 'messages' not in st.session_state:
        st.session_state['messages'] = [{"role": "assistant", 
                                        "content": "ì•ˆë…•í•˜ì„¸ìš”! ì£¼ì–´ì§„ ë¬¸ì„œì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹  ê²ƒì´ ìˆìœ¼ë©´ ì–¸ì œë“  ë¬¼ì–´ë´ì£¼ì„¸ìš”!"}]

    for message in st.session_state.messages:
        with tab2.chat_message(message["role"]):
            tab2.markdown(message["content"])

    history = StreamlitChatMessageHistory(key="chat_messages")

    # Chat logic
    query = tab2.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    if query:
        st.session_state.messages.append({"role": "user", "content": query})

        with tab2.chat_message("user"):
            tab2.markdown(query)

        with tab2.chat_message("assistant"):
            chain = st.session_state.conversation
            if chain is None:
                st.warning('í•™ìŠµëœ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.')
                st.stop()

            with st.spinner("Thinking..."):
                result = chain({"question": query})
                with get_openai_callback() as cb:
                    st.session_state.chat_history = result['chat_history']
                response = result['answer']
                source_documents = result['source_documents']

                tab2.markdown(response)
                with tab2.expander("ì°¸ê³  ë¬¸ì„œ í™•ì¸"):
                    tab2.markdown(source_documents[0].metadata['source'], help = source_documents[0].page_content)
                    tab2.markdown(source_documents[1].metadata['source'], help = source_documents[1].page_content)
                    tab2.markdown(source_documents[2].metadata['source'], help = source_documents[2].page_content)


if __name__ == '__main__':
    main()